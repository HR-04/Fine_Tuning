{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 2.8.0 requires nbconvert>=6.4.4, which is not installed.\n",
      "jupyter-server 2.8.0 requires nbformat>=5.3.0, which is not installed.\n",
      "nltk 3.8.1 requires click, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-server in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (2.8.0)\n",
      "Collecting jupyter-server\n",
      "  Downloading jupyter_server-2.14.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (3.7.1)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (23.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\admin\\torch-gpu\\lib\\site-packages (from jupyter-server) (3.1.3)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (5.7.2)\n",
      "Collecting jupyter-events>=0.9.0 (from jupyter-server)\n",
      "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (0.4.4)\n",
      "Collecting nbconvert>=6.4.4 (from jupyter-server)\n",
      "  Using cached nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting nbformat>=5.3.0 (from jupyter-server)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (7.4.0)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\admin\\torch-gpu\\lib\\site-packages (from jupyter-server) (24.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (0.17.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (2.0.12)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\admin\\torch-gpu\\lib\\site-packages (from jupyter-server) (26.0.3)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (0.17.1)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-server) (5.14.3)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio>=3.1.0->jupyter-server) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio>=3.1.0->jupyter-server) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from anyio>=3.1.0->jupyter-server) (1.2.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from argon2-cffi>=21.1->jupyter-server) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\torch-gpu\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-client>=7.4.4->jupyter-server) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server) (4.2.1)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server) (306)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (4.18.4)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-events>=0.9.0->jupyter-server) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-events>=0.9.0->jupyter-server) (6.0.1)\n",
      "Requirement already satisfied: referencing in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-events>=0.9.0->jupyter-server) (0.30.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-events>=0.9.0->jupyter-server) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jupyter-events>=0.9.0->jupyter-server) (0.1.1)\n",
      "Collecting beautifulsoup4 (from nbconvert>=6.4.4->jupyter-server)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server) (0.7.1)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=6.4.4->jupyter-server)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server) (3.0.2)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert>=6.4.4->jupyter-server)\n",
      "  Using cached nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server) (2.18.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from nbformat>=5.3.0->jupyter-server) (2.18.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server) (0.5.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\admin\\torch-gpu\\lib\\site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (2023.7.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (0.9.2)\n",
      "Requirement already satisfied: fqdn in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (2.4)\n",
      "Requirement already satisfied: uri-template in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server) (2.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server) (2.8.19.14)\n",
      "Downloading jupyter_server-2.14.1-py3-none-any.whl (383 kB)\n",
      "   ---------------------------------------- 0.0/383.4 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/383.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 112.6/383.4 kB 1.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 143.4/383.4 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 256.0/383.4 kB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 307.2/383.4 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 383.4/383.4 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Using cached nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 1.5 MB/s eta 0:00:00\n",
      "Using cached nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: websocket-client, jupyterlab-pygments, beautifulsoup4, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 1.6.4\n",
      "    Uninstalling websocket-client-1.6.4:\n",
      "      Successfully uninstalled websocket-client-1.6.4\n",
      "  Attempting uninstall: jupyter-events\n",
      "    Found existing installation: jupyter-events 0.8.0\n",
      "    Uninstalling jupyter-events-0.8.0:\n",
      "      Successfully uninstalled jupyter-events-0.8.0\n",
      "  Attempting uninstall: jupyter-server\n",
      "    Found existing installation: jupyter_server 2.8.0\n",
      "    Uninstalling jupyter_server-2.8.0:\n",
      "      Successfully uninstalled jupyter_server-2.8.0\n",
      "Successfully installed beautifulsoup4-4.12.3 jupyter-events-0.10.0 jupyter-server-2.14.1 jupyterlab-pygments-0.3.0 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 websocket-client-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyter-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (3.8.1)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\torch-gpu\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\torch-gpu\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Installing collected packages: click\n",
      "Successfully installed click-8.1.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flask-sqlalchemy 3.0.5 requires sqlalchemy>=1.4.18, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                         2.3.1+cu121\n",
      "torchaudio                    2.3.1+cu121\n",
      "torchvision                   0.18.1+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip list | findstr torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: bitsandbytes\n",
      "Version: 0.40.2\n",
      "Summary: k-bit optimizers and matrix multiplication routines.\n",
      "Home-page: https://github.com/TimDettmers/bitsandbytes\n",
      "Author: Tim Dettmers\n",
      "Author-email: dettmers@cs.washington.edu\n",
      "License: MIT\n",
      "Location: c:\\users\\admin\\torch-gpu\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/Users/ADMIN/torch-gpu/lib'), WindowsPath('C')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('C'), WindowsPath('/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/matplotlib_inline.backend_inline'), WindowsPath('module')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=121, Highest Compute Capability: 8.6.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary c:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Set environment variables for CUDA 12.1\u001b[39;00m\n\u001b[0;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_PATH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MatmulLtState,\n\u001b[0;32m      9\u001b[0m     bmm_cublas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     matmul_4bit\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\research\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     switchback_bnb,\n\u001b[0;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[0;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\research\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\research\\nn\\modules.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, device, dtype, nn\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalOptimManager\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n\u001b[0;32m     11\u001b[0m T \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.nn.Module\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\optim\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\cextension.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m     CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mgenerate_instructions()\n\u001b[0;32m     19\u001b[0m     CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mprint_log_stack()\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m    python -m bitsandbytes\u001b[39m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     28\u001b[0m lib\u001b[38;5;241m.\u001b[39mcadam32bit_grad_fp32 \u001b[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n\u001b[0;32m     29\u001b[0m lib\u001b[38;5;241m.\u001b[39mget_context\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mc_void_p\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from bitsandbytes import cuda_setup\n",
    "\n",
    "# Set environment variables for CUDA 12.1\n",
    "os.environ['CUDA_PATH'] = 'C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1'\n",
    "os.environ['PATH'] += ';C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1/bin'\n",
    "os.environ['BITSANDBYTES_CUDA_VERSION'] = '121'\n",
    "  \n",
    "# Verify environment variables\n",
    "print(\"CUDA_PATH:\", os.environ.get('CUDA_PATH'))\n",
    "print(\"PATH:\", os.environ.get('PATH'))\n",
    "\n",
    "# Check CUDA availability in PyTorch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "    print(\"Current CUDA device:\", torch.cuda.current_device())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# Example usage of bitsandbytes\n",
    "print(\"bitsandbytes version:\", cuda_setup.__version__)\n",
    "cuda_setup.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('C'), WindowsPath('/Users/ADMIN/torch-gpu/lib')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/matplotlib_inline.backend_inline'), WindowsPath('module')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 8.6.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary c:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:166: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n",
      "c:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:166: UserWarning: C:\\Users\\ADMIN\\torch-gpu did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.training_args because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\transformers\\utils\\import_utils.py:1099\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\transformers\\training_args.py:67\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AcceleratorState, PartialState\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedType\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\accelerate\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.21.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     cpu_offload,\n\u001b[0;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\accelerate\\accelerator.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\accelerate\\checkpointing.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradScaler\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     MODEL_NAME,\n\u001b[0;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[0;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[0;32m     28\u001b[0m     SCALER_NAME,\n\u001b[0;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[0;32m     30\u001b[0m     get_pretty_name,\n\u001b[0;32m     31\u001b[0m     is_tpu_available,\n\u001b[0;32m     32\u001b[0m     is_xpu_available,\n\u001b[0;32m     33\u001b[0m     save,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tpu_available(check_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\accelerate\\utils\\__init__.py:131\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    123\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[0;32m    124\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m         HfDeepSpeedConfig,\n\u001b[0;32m    129\u001b[0m     )\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbnb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\accelerate\\utils\\bnb.py:42\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bnb_available():\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MatmulLtState,\n\u001b[0;32m      9\u001b[0m     bmm_cublas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     matmul_4bit\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\research\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     switchback_bnb,\n\u001b[0;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[0;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\research\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\research\\nn\\modules.py:8\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalOptimManager\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\optim\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\bitsandbytes\\cextension.py:20\u001b[0m\n\u001b[0;32m     19\u001b[0m     CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mprint_log_stack()\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m    python -m bitsandbytes\u001b[39m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     28\u001b[0m lib\u001b[38;5;241m.\u001b[39mcadam32bit_grad_fp32 \u001b[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     AutoModelForCausalLM,\n\u001b[0;32m      6\u001b[0m     AutoTokenizer,\n\u001b[0;32m      7\u001b[0m     BitsAndBytesConfig,\n\u001b[0;32m      8\u001b[0m     HfArgumentParser,\n\u001b[0;32m      9\u001b[0m     TrainingArguments,\n\u001b[0;32m     10\u001b[0m     pipeline,\n\u001b[0;32m     11\u001b[0m     logging,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, PeftModel\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\transformers\\utils\\import_utils.py:1089\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1089\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\torch-gpu\\lib\\site-packages\\transformers\\utils\\import_utils.py:1101\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.training_args because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
